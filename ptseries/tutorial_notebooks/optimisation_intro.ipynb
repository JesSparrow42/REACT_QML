{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Getting Started with the Binary Bosonic Solver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "A photonic quantum processor can be used to solve combinatorial optimisation problems using ORCA's binary bosonic solver (BBS) algorithm. This is a type of variational quantum algorithm, in which the distribution of photons at the output of a PT Series device is mapped to a binary string, a *cost function* is calculated for these strings, and a classical optimisation loop is used to find the beam splitter parameters in the PT Series that generate a state that minimises the cost function. Here, we assume that non-number resolving detectors are used. In other words, if there is more than one photon in a mode at the output, this just returns a value '1'. We then use parametrisable bit flips which flip each of the output bits from this distribution with a given probability. These probabilities, and the angles in the beamsplitter, are trainable parameters. Over the course of the algorithm we train them to give better results.\n",
    "\n",
    "<center><img src=\"figures/binary_bosonic_solver_scheme.png\" alt=\"Hybrid GAN\" width=\"700\"/></center>\n",
    "<center>Figure 1: Overview of ORCA's algorithm for solving binary optimisation problems.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "In this notebook, we will cover the following:\n",
    "- Detailed setup of the BBS algorithm to solve a simple optimisation task\n",
    "- Using a `logger` object to store training data\n",
    "- Setup of a *knapsack problem* with constraints and solving it with BBS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "The following code block does all of the relevant imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "from ptseries.algorithms.binary_solvers import BinaryBosonicSolver\n",
    "from ptseries.common.logger import Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Setting Up the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "In the following section we will go through a simple example of an optimisation problem, where we will show how to set up the BBS algorithm to solve a simple problem. We will first consider a problem where it is simple to figure out the optimal solution. We're going to look at a solution space of length $6$ binary strings. We set a binary string $s$ which we will call the 'solution vector' and then we'll task ourselves with finding the length $6$ binary string $v$ that minimises the value: $$v \\cdot \\hat{s} - v \\cdot s $$\n",
    "where $\\hat{s}$ is the vector $s$ with all of it's bits flipped (i.e. 1s sent to 0s and vice versa). The '$\\cdot$' here represents the *dot product* between two vectors. In this case, the solution (the $v$ which minimises this value) will be exactly equal to $s$. We will go through how to set up the BBS algorithm for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "We first define our solution_vector $s$ and the problem size (length of bit strings we consider). Then, we set the *cost function* which calculates the value we're trying to minimise, taking as input a binary string and outputting a calculation of the formula we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the solution vector s\n",
    "solution_vector = np.array([1, 0, 1, 0, 1, 0, 1, 0])\n",
    "\n",
    "# Calculates the length of bit strings we will be considering for solutions\n",
    "problem_size = len(solution_vector)\n",
    "\n",
    "\n",
    "# Defines our cost function. We take a bit string as input, and then output the value of the cost function calculated at that bit string.\n",
    "# In this case, this is taking the dot product formula defined above.\n",
    "def cost_fn(bit_str):\n",
    "    # Stores the value of s^ : the solution vector s with all of the bits flipped\n",
    "    flipped_solution_vector = ~solution_vector % 2\n",
    "\n",
    "    # Returns the cost function defined above calculated with 'bit_str' in place of v and 'solution_vector' in place of s\n",
    "    return -np.dot(solution_vector, bit_str) + np.dot(flipped_solution_vector, bit_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "In the following code block, we will define a `logger` object from the SDK which keeps track of the training data from the BBS algorithm. In particular, the algorithm is trying to minimise a 'loss function' that defines how good the solutions considered are. Here, the loss function is equal to the averages of the cost functions calculated for all of the output bit strings during a single iteration of the algorithm. The logger keeps track of these values after each update step.\n",
    "\n",
    "We next instantiate the `BinaryBosonicSolver` object as the variable `bbs`. When doing this, we need to tell the algorithm the `problem size` (length of bit strings we consider, labelled `pb_dim` i.e. problem dimension), the cost function we're using (labelled `objective`) and also the parameters of the time bin interferometer that we'll be using (`tbi_params`). In this case, we'll set our time bin interferometer to have a single loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(log_dir=None)\n",
    "\n",
    "bbs = BinaryBosonicSolver(\n",
    "    pb_dim=problem_size, objective=cost_fn, tbi_params={\"tbi_type\": \"single-loop\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Next, we will call the `.train` method of the bbs algorithm. We set the following parameters:\n",
    "- `learning_rate`: Defines the scaling of the update steps we take for the parametrisable angles inside the tbi\n",
    "- `learning_rate_flip`: Defines the scaling of the update steps we take for the parametrisable bit flips\n",
    "- `updates`: Number of iterations we do of the algorithm, after each one updating the parameters\n",
    "- `print_frequency`: Frequency with which we print out the average cost function values the algorithm is achieving\n",
    "- `logger`: Defines the logger we'll be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs.train(\n",
    "    learning_rate=5e-2,\n",
    "    learning_rate_flip=1e-1,\n",
    "    updates=200,\n",
    "    print_frequency=40,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "At the end of this training cycle, we see that the loss being achieved has gone down, indicating that the bit strings being produced by our algorithm are closer to the true solution. Now, we output the best solution found by the algorithm, meaning the bit string encountered which had the lowest cost function. We use the `config_min_encountered` member to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sol = bbs.config_min_encountered\n",
    "\n",
    "print(f\"Best solution found is {best_sol} with cost function value {cost_fn(best_sol)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "We see that the solution the BBS algorithm found is exactly equal to the solution vector that we defined initially. In other words, the algorithm has found the solution. Note also that the loss the algorithm was achieving near the end of training was very close to the true minimal value of -4. This means that the algorithm, near the end of training, had most of its binary string outputs equal to the true solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### (Aside) Using the Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "The `logger` stored the data about all of the average cost function values we observed during training. We can then use it to nicely plot these values to investigate the performance of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the number of updates as a list of values we will use to plot the x axis\n",
    "x_values = list(map(int, logger.logs[\"energy_avg\"].keys()))\n",
    "\n",
    "# Gets the average cost function value calculated at each update step\n",
    "cost_fn_avg = list(logger.logs[\"energy_avg\"].values())\n",
    "\n",
    "plt.plot(x_values, cost_fn_avg)\n",
    "\n",
    "plt.xlabel(\"Update Number\")\n",
    "plt.ylabel(\"Average Cost Function Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "In fact, the logger stores even more information. The logger has kept track of the highest and lowest cost function values encountered at each update step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Setting up the Algorithm - A Simple Knapsack Problem\n",
    "Here we will now look at a slightly more complicated optimisation task, and reviewing how we set up the BBS algorithm to find good solutions. In this example, we will consider a simple instance of a *knapsack problem*. Here, the 0 and 1 values in a bit string represent whether we take an item or not. Each item gives us value, but also adds weight to the knapsack. We want to choose which items to take to get the most value, but also not go over the amount of weight we can carry in the knapsack.\n",
    "\n",
    "We will consider problems where we have $m$ items we could take, each having a weight $w_i$ and value $v_i$. Our knapsack has a maximum weight capacity of $M$. We want to maximise the sum of the values we get from the items we take, denoted by $V$. To define possible solutions for the problem, we'll use length $m$ bit strings $x_0 x_1 ... x_{m-1}$ where, if $x_i = 1$, it means that we're taking item $i$. We can formulate this problem precisely as wanting to find the bit string giving us:\n",
    "$$\\max V = \\sum_i v_i x_i  \\quad  \\text{s.t.} \\quad \\sum_i w_i x_i \\le M$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "We'll now consider an exact problem, where we'll set $m = 7$, giving us the number of items (i.e. length of bit strings) that we'll consider, and we'll set some $v_i$ and $w_i$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the max weight capacity for the knapsack\n",
    "M = 20\n",
    "\n",
    "# Defines the size of the problem\n",
    "problem_size = 7\n",
    "\n",
    "# Sets the values and weights for each item\n",
    "values = np.array([5, 7, 1, 10, 9, 12, 13], dtype=int)\n",
    "\n",
    "weights = np.array([10, 5, 2, 6, 8, 7, 4], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Unlike the previous example, we can't just make our cost function equal to the value of items a bit string takes, as then the best solution would clearly be to just take every single item. We need to dissuade the algorithm from considering solutions that break the weight constraint. We will do this by adding a penalty term to the cost function, that adds a big penalty if a bit string encodes a solution going over the weight limit. \n",
    "\n",
    "This time, we also need to feed in the values, weights and weight capacity we defined into the function. So, we will create a function with two layers. The first layer `cost_fn_gen` will create the cost function we want with the specified values. This way, we can easily generate the same cost function for new item values and weights. It's important to note that here, we calculate the value associated with taking certain items but then the cost function returns the negative of this value. This is because, for the knapsack problem, we want to get the most valuable choice of items but the BBS algorithm is trying to minimise the cost function. Thus, we need to take the negative of the value_total at the end for the algorithm to find solutions maximising the value total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a cost function with the desired parameters\n",
    "def cost_fn_gen(values, weights, weight_limit, penalty):\n",
    "    def cost_fn(bit_str):\n",
    "        # Calculates the total value associated with taken items\n",
    "        value_total = np.dot(values, bit_str)\n",
    "\n",
    "        # Calculates the total weight associated with taken items\n",
    "        weight_total = np.dot(weights, bit_str)\n",
    "\n",
    "        # If the solution being considered goes over the weight limit, we add a big penalty term\n",
    "        if weight_total > weight_limit:\n",
    "            value_total += -penalty\n",
    "\n",
    "        # Returns the negative of the value total\n",
    "        return (-1) * value_total\n",
    "\n",
    "    # Returns the cost function we've generated\n",
    "    return cost_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Now, using this generator, we'll create the cost function that we want, and we will take a penalty term of 50 meaning that any solution which goes over the weight limit will be heavily penalised. Thus, the BBS algorithm will steer away from such solutions as they will have a low cost function value. Then, we set up the BBS algorithm and train it exactly as we did in the first example. This time, we do 400 update steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_fn = cost_fn_gen(values=values, weights=weights, weight_limit=M, penalty=50)\n",
    "\n",
    "bbs = BinaryBosonicSolver(\n",
    "    pb_dim=problem_size, objective=cost_fn, tbi_params={\"tbi_type\": \"single-loop\"}\n",
    ")\n",
    "\n",
    "bbs.train(learning_rate=5e-2, learning_rate_flip=1e-1, updates=400, print_frequency=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Again, we output the best solution found, with the exact same code as in the first example except we take the negative of the cost function to make up for the fact that we were taking the negative of the value earlier. We also output the weight of the solution we've found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sol = bbs.config_min_encountered\n",
    "\n",
    "print(\n",
    "    f\"Best solution found is {best_sol} with a value of {(-1) * cost_fn(best_sol)}, while having weight {np.dot(weights, best_sol)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "And there we have it! We found a solution with value 36 and weight 19. In fact, if you go through the optimisation problem by hand you can see that this is the exact solution to the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "In this notebook we've gone through two examples of how to setup the BBS algorithm to solve binary optimisation tasks which have a non-QUBO formulation. There are three more advanced notebooks about the BBS algorithm, found within the `tutorial_notebooks/optimisation_notebooks` folder each of which looks at a different example optimisation task in depth.\n",
    "- `QUBO_&_max_cut.ipynb`: Introduces QUBO formulated problems, and goes over solving a max-cut problem in QUBO formulation\n",
    "- `route_optimisation.ipynb`: Introduces a travelling salesman task, and how to solve it using the BBS algorithm\n",
    "- `workshop_optimisation.ipynb`: Considers a larger scale knapsack problem to the one seen above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
