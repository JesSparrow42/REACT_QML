{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PT-1 demonstration notebook\n",
    "\n",
    "This notebook demonstrates the basic functionalities of the PT-1, including how to connect, perform experiments, and run machine learning algorithms. Before using this notebook make sure that the PT-1 hardware is ready by following the device's manual. The current status of the PT Series hardware is indicated on the status page.\n",
    "\n",
    "**This notebook assumes you are running the SDK on the on-premise computer supplied with the PT-1.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "from ptseries.models import PTLayer\n",
    "from ptseries.tbi import create_tbi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a connection to the device must be opened. We can do this by calling the `create_tbi` function with the `tbi_type` set to PT-1. Note that the object has some differences to the simulated backends you may have used previously. Specifically, you cannot specify parameters such as beam splitter loss because this is now a property of the device. For a full comparison, please consult the SDK documentation. Make sure to replace the value of `x.x.x.x` with the actual address.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can either use the a previously set environment variable ORCA_ACCESS_URL (see the documentation)\n",
    "# or pass the url directly to the tbi_params\n",
    "tbi_params = {\n",
    "    \"tbi_type\": \"PT-1\",\n",
    "    \"url\": \"http://x.x.x.x\",\n",
    "}\n",
    "\n",
    "time_bin_interferometer = create_tbi(**tbi_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "\n",
    "Once the above methods tell you the hardware is ready to use, you can run your first experiment on this boson sampler! This can be done by calling the sample method. Note that the number of beam splitter angles, specified by 'theta_list' will always be the number of modes minus one.\n",
    "\n",
    "The next two cells draw the circuit representation of the PT-1 for our target state and then produce 200 samples from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_state = (1, 0, 0)  # 1 photon in 3 modes\n",
    "theta_list = [np.pi / 4] * (len(input_state) - 1)  # 50/50 beam splitters\n",
    "n_samples = 200\n",
    "\n",
    "time_bin_interferometer.draw(input_state=input_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = time_bin_interferometer.sample(\n",
    "    input_state=input_state,\n",
    "    theta_list=theta_list,\n",
    "    n_samples=n_samples,\n",
    ")\n",
    "print(samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you have just created and measured a quantum state where the single photon has roughly 50% probability of being measured in the first mode, and 25% probability of being measured in the two other modes. Deviations from these probabilities are caused by experimental imperfections such as loss in the loop.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a PT-1\n",
    "\n",
    "The angles that define the reflectivity of the beam splitters are trainable using PyTorch. To do this we must define a model, analogous to a neural network, called PTlayer. This model uses a custom extension of PyTorch's Autograd to interact with the PT-1.\n",
    "In this example we use this feature to train the PT-1 to route a photon from the first mode to the last mode. First we define the model, with a single photon input into the first mode, and view the output of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PTLayer(\n",
    "    (1, 0, 0, 0),  # The input state\n",
    "    observable=\"avg-photons\",\n",
    "    in_features=0,\n",
    "    n_samples=100,\n",
    "    tbi_params=tbi_params,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "outputs_initial = model()\n",
    "print(outputs_initial)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the beam splitter values in PTLayer are initialised randomly, so the input photon initially gets randomly distributed among all four modes.\n",
    "\n",
    "Next we define how we train the model. Because the PT-1 uses PyTorch, you can use optimizers and loss functions just as you would for a classical model. Here we also define our objective, which is routing the photon into the last mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "objective = torch.tensor([[0.0, 0.0, 0.0, 1.0]], dtype=torch.float32)\n",
    "\n",
    "loss = torch.nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train the model for a given number of epochs, resetting the gradients at each step. The output from the model is now a photon routed to the last mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "for i in range(iterations):\n",
    "    optimizer.zero_grad()\n",
    "    loss_value = loss(model(), objective)\n",
    "    loss_value.backward()\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print(\"Loss at iteration {}: \".format(i), loss_value.item())\n",
    "\n",
    "model.eval()\n",
    "outputs_final = model()\n",
    "print(\"Final output state: \", outputs_final)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Data\n",
    "\n",
    "You can automatically save data from the PT-1 by specifying save_dir when running the sampling command. This can be useful if you would like to export the sample for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = time_bin_interferometer.sample(\n",
    "    input_state=(1, 0, 0, 0), theta_list=[np.pi / 4] * 3, n_samples=100, save_dir=\"data\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Classifier\n",
    "\n",
    "For an example showing how to use the PT-1 for classification, we suggest that you open and run the `quantum_variational_classification` notebook. To run this model on the PT-1, simply modify the line where you instantiate the model to `model = Model(tbi_params={\"tbi_type\": \"PT-1\", \"url\": \"http://x.x.x.x\"})`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
